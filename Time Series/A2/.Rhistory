summary( prcomp(Z))
screeplot(prcomp(Z),npcs = 6, type = "lines")
# Regression with all standardized PCs as the explanatory variables
##############################################################################
PC.model.new.1 = lm(BP.data$BP ~  W.new[,1] + W.new[,2] + W.new[,3] + W.new[,4] + W.new[,5]+ W.new[,6])
summary(PC.model.new.1)  # W2 and W5 seem not to be significant
# Let's remove W3.new and W5.new
PC.model.new.2 = lm(BP.data$BP ~  W.new[,1] + W.new[,2] + W.new[,4] + W.new[,6])
summary(PC.model.new.2)
# Note that removing PCs from the model does not change the coefficients!
vif(PC.model.new.2)
# check the importance of each variable in standardized PCs:
round(Vec.new[,1],3)   # all variables contribute to the first PC
round(Vec.new[,2],3)   # stress vs (weight and BSA)
round(Vec.new[,3],3)   # Dur dominates the third PC  (perhaps vs stress)
round(Vec.new[,4],3)   # Age dominates the fourth PC (perhaps vs stress)
round(Vec.new[,5],3)   # Pulse vs (BSA and stress)
round(Vec.new[,6],3)   # Weight vs (BSA and pulse)
# the correlations between PCs and variables also indicate importance:
cor.WX = function(mat){
vals= mat
rownames(vals) = paste("X", 1:nrow(mat), sep="")
colnames(vals) = paste("W", 1:nrow(mat), sep="")
for(i in 1: ncol(vals)){
val= t(eigen(mat)$vectors[,i])* sqrt( eigen(mat)$values[i])
vals[,i] = val/sqrt(diag(mat))
}
return(vals)
}
cor.WX(R)
#########################################
# Principal Components Regression
#########################################
# Recall that
# We had data on blood pressure, age, weight, body surface area, duration of hypertension,
# basal  pulse, stress index for 20 individuals with high blood pressure
#########################################
BP.data= read.table(file="bp.txt", header=TRUE)[,-1]
#########################################
# Principal Components Regression
#########################################
# Recall that
# We had data on blood pressure, age, weight, body surface area, duration of hypertension,
# basal  pulse, stress index for 20 individuals with high blood pressure
#########################################
BP.data= read.table(file="bp.txt", header=TRUE)[,-1]
#########################################
# Principal Components Regression
#########################################
# Recall that
# We had data on blood pressure, age, weight, body surface area, duration of hypertension,
# basal  pulse, stress index for 20 individuals with high blood pressure
#########################################
BP.data= read.table(file="E:\OneDrive\Document\UofT\Last Year\Winter\STA437\Scriptbp.txt", header=TRUE)[,-1]
#########################################
# Principal Components Regression
#########################################
# Recall that
# We had data on blood pressure, age, weight, body surface area, duration of hypertension,
# basal  pulse, stress index for 20 individuals with high blood pressure
#########################################
BP.data= read.table(file="E:/OneDrive/Document/UofT/Last Year/Winter/STA437/Script/bp.txt", header=TRUE)[,-1]
BP.data
n=20
colnames(BP.data)
X= as.matrix(BP.data[2:7])      # exclude the response variable!!
# Obtain the sample mean vector and sample covariance matrix of X:
x.bar = apply(X,2,mean)
x.bar
S= cov(X)
S
round(S, 3)
# the scales are quite different, suggesting that we may be better off using R to get the PCs
# nevertheless, let's continue with S. We will redo the analysis with R later!
# Principal Components:
#######################################
# to get the PCs, first find the eigenvalues and eigenvectors
Val = eigen(S)$values
Vec = eigen(S)$vectors
Val
# obtain correlation matrix
R = cor(X)
cov(Z)  # they should be the same!
# obtain eigenvalues and eigenvectors of R
Val.new = eigen(R)$values
Z=X
for(i in 1:6){
Z[,i] = (X[,i]-x.bar[i])/sqrt(diag(S)[i])
}
# obtain correlation matrix
R = cor(X)
cov(Z)  # they should be the same!
# obtain eigenvalues and eigenvectors of R
Val.new = eigen(R)$values
Val.new
for(i in 1:6){
for(j in 1:20){
W[j,i] = Vec[,i] %*% ( X[j,] -x.bar)  # centered PCs
}}
colnames(W) = paste("W", 1:6, sep="")
plot(data.frame(W))
round( cor(W),3)
W = X  # just to create a data matrix of the same size of X
for(i in 1:6){
for(j in 1:20){
W[j,i] = Vec[,i] %*% ( X[j,] -x.bar)  # centered PCs
}}
colnames(W) = paste("W", 1:6, sep="")
plot(data.frame(W))
round( cor(W),3)
round(apply(W, 2, mean),3)
plot(Val, type="b")  # suggests keeping the first PC only!
round( Val/sum(Val),3)  # 97.3 % of the sample variation in X is explained by the first PC.
summary( prcomp(X,cov.mat=TRUE))
x.bar= c(155.60, 14.70)
S= matrix(c(7476.45, 303.62,303.62, 26.19),nrow=2)
################################################################################
# a) Determine the sample PCs and their variances:
################################################################################
eigen(S)
# Thus we have sample PCs:
# W1 = -0.999 X1 - 0.041 X2      OR     W1 = 0.999 X1 + 0.041 X2
# W2 = -0.041 X1 + 0.991 X2      OR     W2 = 0.041 X1 - 0.991 X2
# Variances of sample PCs are given by:
eigen(S)$values
# Var(W1) = 7488.80293
# Var(W2) = 13.83707
################################################################################
# b) Find the proportion of total variance explained by W1
################################################################################
# Proportion of total variance explained by W1 is 0.998
eigen(S)$values[1]/ sum(eigen(S)$values)
################################################################################
# c) Sketch the constant density ellipe (x-x.bar)' S^{-1} (x-x.bar) = 1.4 and
# indicate the sample PCs on your graph
################################################################################
library(ellipse)
plot(ellipse(S,centre=x.bar, t= sqrt(1.4)),type='l', col=1, asp=1)
points(x.bar[1],x.bar[2],col=1, pch=20)
Val= eigen(S)$values
Vec = eigen(S)$vectors
hlength.1 =  sqrt(Val[1]* 1.4)
hlength.2 =  sqrt(Val[2]* 1.4)
v1= hlength.1 * Vec[,1]
v2= hlength.2 * Vec[,2]
segments(  x.bar[1] -v1[1],   x.bar[2] -v1[2],   x.bar[1] + v1[1],   x.bar[2] + v1[2], col=4)
segments(  x.bar[1] -v2[1],   x.bar[2] -v2[2],   x.bar[1] + v2[1],   x.bar[2] + v2[2], col=4)
################################################################################
# d) Compute Corr(W1,X1) and Corr(W1,X2)
################################################################################
cor.WX = function(mat){
vals= mat
rownames(vals) = paste("X", 1:nrow(mat), sep="")
colnames(vals) = paste("W", 1:nrow(mat), sep="")
for(i in 1: ncol(vals)){
val= t(eigen(mat)$vectors[,i])* sqrt( eigen(mat)$values[i])
vals[,i] = val/sqrt(diag(mat))
}
return(vals)
}
cor.WX(S)[,1]
cor.WX(S)
# Here we will revisit the blood pressure data and illustrate regression with principal components
#########################################
# Principal Components Regression
#########################################
# Recall that
# We had data on blood pressure, age, weight, body surface area, duration of hypertension,
# basal  pulse, stress index for 20 individuals with high blood pressure
#########################################
BP.data= read.table(file="E:/OneDrive/Document/UofT/Last Year/Winter/STA437/Script/bp.txt", header=TRUE)[,-1]
BP.data
n=20
colnames(BP.data)
X= as.matrix(BP.data[2:7])      # exclude the response variable!!
# Obtain the sample mean vector and sample covariance matrix of X:
x.bar = apply(X,2,mean)
x.bar
S= cov(X)
S
round(S, 3)
# the scales are quite different, suggesting that we may be better off using R to get the PCs
# nevertheless, let's continue with S. We will redo the analysis with R later!
# Principal Components:
#######################################
# to get the PCs, first find the eigenvalues and eigenvectors
Val = eigen(S)$values
Val
Val[1]
Val[1]/sum[Val]
Val[1]/sum(Val）
Val[1]/sum(Val)
Val
Val.new
Val[1]/sum(Val)
product(1:23)/24^24
prod(1:23)/24^24
a <- c(15,10,10,14,7,11,9)
a
a <-rbind(a,c(9,8,15,9,5,10,17))
a
a <- rbind(a,c(10,10,8,19,15,11,12))
a
a <- rbind(a,c(12,11,10,10,12,17,8))
a
a <- rbind(a,c(11,14,11,10,9,12,10))
a
a <-c(8,14,11,10,11,13,12,11)
a <- rbind(a,c(11,16,14,13,9,10,14,16))
a
a <- rbind(a,c(10,14,15,11,13,18,6,11))
a
a <- rbind(a,c(7,12,17,8,11,9,11,13))
a
a <- rbind(a,c(8,13,8,11,13,13,9,14))
a
a <- rbind(a,c(10,14,13,10,16,6,14,13))
mean(a)
a[,1]
for(i in 1:8){}
for(i in 1:8){}
for(i in 1:8){mean(a[,i])}
for(i in 1:8){print(mean(a[,i]))}
a <- rbind(a,c(9,14,14,8,6,12,13,11))
for(i in 1:8){print(mean(a[,i]))}
var(for(i in 1:8){print(mean(a[,i]))})
a <- rbind(a,c(12,11,10,10,13,13,7,13))
a
a <- rbind(a,c(10,9,11,11,12,12,17,4))
for(i in 1:8){print(mean(a[,i]))}
a <- rbind(a,c(11,17,14,14,8,16,14,6))
a <- rbind(a,c(14,14,9,10,12,12,9,10))
for(i in 1:8){print(mean(a[,i]))}
for(i in 1:10){print(sum(a[i,]))}
m<c()
m<-c()
for(i in 1:8){c(m,mean(a[,i]))}
m
c(m,1)
m
for(i in 1:8){rbind(m,mean(a[,i]))}
m
for(i in 1:8){append(m,mean(a[,i]))}
m
for(i in 1:8){m[i]<-mean(a[,i])}
m
var(m)
for(i in 1:8){m[i]<-mean(a[1:5,][,i])}
var(m)
for(i in 1:8){m[i]<-mean(a[1:9,][,i])}
var(m)
m
for(i in 1:8){m[i]<-mean(a[1:10,][,i])}
m
nrow(a)
for(i in 1:8){m[i]<-mean(a[1:11,][,i])}
m
var(m)
a
colnames(a)
b <- as.data.frame(a)
b
rownames(b) <-c(1:11)
b
colnames(b) <- ("苹果","卷心菜","新鲜牛肉","风干肉","面包","小麦","橄榄","蜂蜜")
colnames(b) <- ("苹果","卷心菜","新鲜牛肉","风干肉","面包","小麦","橄榄","蜂蜜")
colnames(b) <- c("苹果","卷心菜","新鲜牛肉","风干肉","面包","小麦","橄榄","蜂蜜")
b
write.table("搞事.txt",'E:/')
write.table("搞事.txt",'E:\')
)
n)
a
stop
)
}
/)
\n''
)
getwd()
write.table("搞事.txt")
write.csv("搞事.txt")
write.csv("搞事.txt",'Mount&Blade Warband/')
write.csv("搞事.txt",'/Mount&Blade Warband/')
write.csv("搞事.txt",'G:\单机')
write.csv("搞事.txt",'G:/单机')
?write.csv
write.csv(a,"搞事.txt")
write.csv(b,"搞事.txt")
#load package to use the function 'fa'
library(psych)
# Favourite Subject Example:
# Ref: http://rtutorialseries.blogspot.ca/2011/10/r-tutorial-series-exploratory-factor.html
####################################
data <- read.csv("E:/OneDrive/Document/UofT/LastYear/Winter/STA437/Script/dataset_EFA.csv")
head(data)
corMat <- cor(data) #sample correlation matrix, R
round(corMat,3)
fa.1 = fa(r = corMat, nfactors = 2, rotate = "none", fm = "pa")
fa.1
fa.2 = fa(r = corMat, nfactors = 2, rotate = "varimax", fm = "pa")
fa.2
fa.3 = fa(r = corMat, nfactors = 2, rotate = "oblimin", fm = "pa")
fa.3
knitr::opts_chunk$set(eval = FALSE, message=FALSE, warning=FALSE, echo = FALSE)
# Basic settings
port.number = 1234
base.url = paste("http://localhost:", toString(port.number), "/v1", sep="")
#print(base.url)
version.url = paste(base.url, "version", sep="/")
cytoscape.open = TRUE
tryCatch(expr = { GET(version.url)},
error = function(e) { return (cytoscape.open = FALSE)}, finally =function(r){ return(cytoscape.open = TRUE)})
if(!cytoscape.open){
#try and launch cytoscape
print("Cytoscape is not open.  Please launch cytoscape.")
} else{
cytoscape.version =  GET(version.url)
cy.version = fromJSON(rawToChar(cytoscape.version$content))
print(cy.version)
}
library(RJSONIO)
library(httr)
library(ggplot2)
library(Biobase)
library(RCurl)
library(RCy3)
# Basic settings
port.number = 1234
base.url = paste("http://localhost:", toString(port.number), "/v1", sep="")
#print(base.url)
version.url = paste(base.url, "version", sep="/")
cytoscape.open = TRUE
tryCatch(expr = { GET(version.url)},
error = function(e) { return (cytoscape.open = FALSE)}, finally =function(r){ return(cytoscape.open = TRUE)})
if(!cytoscape.open){
#try and launch cytoscape
print("Cytoscape is not open.  Please launch cytoscape.")
} else{
cytoscape.version =  GET(version.url)
cy.version = fromJSON(rawToChar(cytoscape.version$content))
print(cy.version)
}
# Basic settings
port.number = 1234
base.url = paste("http://localhost:", toString(port.number), "/v1", sep="")
#print(base.url)
version.url = paste(base.url, "version", sep="/")
cytoscape.open = TRUE
tryCatch(expr = { GET(version.url)},
error = function(e) { return (cytoscape.open = FALSE)}, finally =function(r){ return(cytoscape.open = TRUE)})
if(!cytoscape.open){
#try and launch cytoscape
print("Cytoscape is not open.  Please launch cytoscape.")
} else{
cytoscape.version =  GET(version.url)
cy.version = fromJSON(rawToChar(cytoscape.version$content))
print(cy.version)
}
install.packages("cansim")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(cansim)
library(tidyverse)
#student number:1001311626, last digit 6, use Goods-producing sector data, second last digit is even, so data over over Jan 2000 to Dec 2019
ua = get_cansim_vector( "v2057813", start_time = "2000-01-01", end_time = "2019-12-01") %>%
pull(VALUE) %>% ts( start = c(2000,1), frequency = 12)
acf(ua)
pacf(ua)
acf(ua)
pacf(ua)
install.packages("forecast")
library(forecast)
?log
log(2)
log(e^2)
log(2,base =4)
log(1,base =0.9)
log(0.99,base =0.9)
log(0.9,base =1)
log(0.9,base =0.99)
0.9^10
0.9^15
N=500
W = ts(rnorm(N))
acf(W, main = "")
W[-N]
cumsum(W)
W
?window
library(stats)
library(astsa)
install.packages('astsa')
library(astsa)
library(cansim)
library(tidyverse)
library(forecast)
library(Metrics)
library(seasonal)
library(ggplot2)
?filter
?ARMAacf
?sarima
?ar.yw
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(cansim)
library(tidyverse)
library(forecast)
library(Metrics)
library(seasonal)
library(ggplot2)
library(forecast)
library(astsa)
#data import and exploratory plot
data <- read.csv('1001311626.csv')
prices <- ts(data$Canadian.Potato.Prices,frequency = 12)
plot(prices,main = 'Canadian Potato Prices')
par(mfrow=c(1,2))
acf(prices, main = 'ACF plot')
pacf(prices, main = 'PACF plot')
#Decomposition
dc <- decompose(prices,type = c('multiplicative'))
plot(dc)
Remainder <- dc$random
dc <- decompose(prices,type = c('additive'))
plot(dc)
par(mfrow=c(1,2))
acf(Remainder,na.action = na.pass, main = 'Remainder ACF plot')
pacf(Remainder,na.action = na.pass, main = 'Remainder PACF plot')
model.ar <- arima(Remainder, c(14,0,0))
model.auto <- auto.arima(Remainder, seasonal = TRUE, stationary = TRUE)
Box.test(model.ar$residuals,type = c("Ljung-Box"))$p.value
Box.test(model.auto$residuals,type = c("Ljung-Box"))$p.value
sarima(Remainder,2,0,1,P=1,Q=0,S=1)
fore <- forecast(model.ar,h=12)
plot(fore)
out <- c(prices,as.numeric(fore$mean)+as.numeric(tail(dc$seasonal,n=12))+as.numeric(tail(na.omit(dc$trend),n=1)))
write.csv(out,'submission/1001311626.csv',row.names = FALSE,col.names=FALSE)
BoxCox(prices,lambda = 'auto')
model.auto
model.auto <- auto.arima(Remainder, seasonal = FALSE, stationary = TRUE)
model.auto
sarima(Remainder,2,0,1)
sarima(Remainder,14,0,0)
arima(Remainder,oder = c(14,0,0))
arima(Remainder,order = c(14,0,0))
a <- arima(Remainder,order = c(14,0,0))
qqnorm(a$residuals)
qqline(a$residuals)
plot(residual)
plot(a$residuals)
b <- BoxCox(Remainder)
b <- BoxCox(Remainder,lambda='auto')
pacf(b)
pacf(b,na.action = na.pass)
a <- arima(Remainder,order = c(14,0,0))
qqnorm(a$residuals)
qqline(a)
qqline(a$residuals)
auto.arima(a)
auto.arima(ts(a,frequency=12))
auto.arima(ts(as.numeric(a),frequency=12))
auto.arima(ts(as.numeric(unlist(a)),frequency=12))
auto.arima(ts(b),frequency=12))
auto.arima(ts(b,frequency=12))
auto.arima(ts(b),frequency=12),seasonal = FALSE)
auto.arima(ts(b,frequency=12),seasonal = FALSE)
sarima(b, 2,0,1)
sarima(b, 14,0,0)
Box.test(model.ar$residuals)
Box.test(model.auto$residuals)
auto.arima(prices)
sarima(prices,2,0,0,P=0,D=1,Q=2)
sarima(ts(prices,frequency = 12),2,0,0,P=0,D=1,Q=2)
sarima(ts(prices,frequency = 12),2,0,0,P=0,D=1,Q=2,S=12)
auto.arima(Remainder)
sarima(Remainder,2,0,1,P=1,D=0,Q=1,S=12)
sarima(Remainder,14,0,0)
model.auto <- auto.arima(Remainder, seasonal = TRUE, stationary = TRUE)
model.auto
sarima(Remainder,2,0,1,P=1,D=0,Q=1,S=12)
model.auto
model.auto$model
model.auto$fitted
model.auto$arma
model.ar$arma
?auto.arima
model.auto <- auto.arima(Remainder, seasonal = TRUE)
model.auto
sarima(14,0,0)
sarima(Remainder,14,0,0)
sarima(Remainder,2,0,1,P=1,D=0,Q=1,S=12)
sarima(Remainder,14,0,0)
sarima(Remainder,2,0,1,P=1,D=0,Q=1,S=12)
a <- sarima(Remainder,14,0,0)
View(a)
sarima(Remainder,2,0,1,P=1,D=0,Q=1,S=12)
fore <- forecast(model.auto,h=12)
plot(fore)
acf(Remainder,na.action = na.pass, main = 'Remainder ACF plot')
as.numeric(fore$mean)+as.numeric(tail(dc$seasonal,n=12))
prices,as.numeric(fore$mean)+as.numeric(tail(dc$seasonal,n=12))+as.numeric(tail(na.omit(dc$trend),n=1))
as.numeric(fore$mean)+as.numeric(tail(dc$seasonal,n=12))+as.numeric(tail(na.omit(dc$trend),n=1)
)
plot(as.ts(rnorm(300)))
new <- read.csv('submission/1001311626.csv')
getwd()
setwd()
setwd('E:/OneDrive/Document/UofT/LastYear/Summer/STA457/A2')
new <- read.csv('submission/1001311626.csv')
plot(new)
plot(ts(new,frequency = 12))
plot(prices)
