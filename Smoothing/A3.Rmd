---
title: "A3"
author: "Yuhan Hu"
date: "2019/11/9"
output: 
  pdf_document:
    toc: true
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# CO2

## Introduction

We are interested in the changes $CO_2$ concentration from an observatory in Haiwaii. More specifically, we are intersted in whether $CO_2$ concentration is impacted by the following events:
1. the OPEC oil embargo which began in October 1973; 
2. the global economic recessions around 1980-1982;
3. the fall of the Berlin wall almost exactly 30 years ago, preceding a dramatic fall in industrial production in the Soviet Union and Eastern Europe;
4. China joining the WTO on 11 December 2001, which was followed by rapid growth in industrial production;
5. the bankruptcy of Lehman Brothers on 15 September 2008, regarded as the symbolic start of the most recent global financial crisis; and
6. the signing of the Paris Agreement on 12 December 2015, intended to limit CO2 emissions.

## Method

We use non-parametric generalized model from gamma family with log link function to analyze this question. 

$Y_i\sim Gamma(\theta)$ where $log(E(Y))=X_i\beta+U(t_i)+V_i$

$X_i\beta = \sum^{4}_{j=1}\phi_j(x_i)\beta_j+f(x_i)$ and $\phi_1=cos(2\pi x_i),\phi_2=sin(2\pi x_i),\phi_3(x_i)=cos(4\pi x_i),\phi_4(x_i)=sin(4\pi x_i)$ is B-spline fit to the data. 

$y_i$ is the concentration of $CO_2$ measured. $\phi_1$ and $\phi_2$ represent yearly fluctuation per half year, $\phi_3$ and $\phi_4$ represent biyearly fluctuation.

$[U_1...U_T]^T\sim RW2(0,\sigma^2_U)$ is the random effect.

$V_i$ is the random noise.

## Result

All plots related to $CO_2$ are shown in the $CO_2$ section of Appendix.

From the sequence plot we can see that though fluctuating, concentration of $CO_2$ keeps increasing. Since the population of human keeps growing and industrial production never stop, there is no reason that amount of $CO_2$ reduces. Since the overall concentration keeps increasing, we can not answer the research question by this plot.

Fluctuations on sequence plot can be explained by seasonal effect plot. From this plot, we can see that $CO_2$ concentration varies within a year. In addition, the pattern of variation matches pattern of fluctuation on sequence plot. So we can conclude that fluctuations on sequence plot is due to seasonal $CO_2$ concentration variation.

Derivative plot is the plot we are interested in. This plot shows how the rate of change of $CO_2$ concentration varied during past years; thus it can help us analyze impact of the given events. Overall, besides 


Overall, besides China joining WTO in 2010, all events have negative impact on CO2 concentration. More specifically, 

1. OPEC embargo in 1973 reduce the amount of oil consumption, which obviously reduce CO2 emissions. Rate of change in $CO2$ concentration was decreasing after this event. Therefore this event helps decrease $CO_2$ concentration

2.	Global recessions imply reduced industrial activity and consumption, less CO2 emitted to air from factory and oil consumption, so concentration of CO2 increase much slowly. Rate of change in $CO2$ concentration was decreasing after this event. Therefore this event helps decrease $CO_2$ concentration

3.	Fall of Berlin Wall is preceding by a dramatic fall in industrial production in USSR and eastern Europe, thus reduce CO2 emissions. Rate of change in $CO2$ concentration was decreasing after this event. Therefore this event helps decrease $CO_2$ concentration

4.	Rate of change in $CO_2$ concentration decrease slightly after China joined WTO. Then a dramatic increase follows, since this event happeded during a decreasing region and this decreasing region is much shorter than others, we may conclude that this event increase rate of change in $CO_2$ concentration. Therefore this event helps increase $CO_2$ concentration

5.	Though CO2 concentration rate of change is not decreasing after bankruptcy of Lehman Brothers, since the rate of change was increasing before enter this nearly flat region, we can say that CO2 concentration increase slower due to this event. Therefore this event helps increase $CO_2 concentration$

6.	CO2 concentration rate of change does not decrease directly after Paris Agreement. But the rate of change reached its maximum and starts to decrease soon after this events. Since government needs time to accomadate the agreement, it’s reasonable to say that Paris Agreement helps reduce $CO_2$ emissions. 

We also generated a prediction plot, from this plot, we may conclude that $CO_2$ concentration will exceed 420 ppm after 2025.

From the random effect plot, it's clear that random effect is increasing as time Pass, which imply that.

\pagebreak

# Heat

## Introduction

IPCC stated that Human activities are estimated to have caused approximately 1.0°C of global warming above preindustrial levels, with a likely range of 0.8°C to 1.2°C. Global warming is likely to reach 1.5°C between 2030 and 2052 if it continues to increase at the current rate. 

Here we are investigating data from Sable Island, off the coast of Nova Scotia, and trying to figure out whether the data from Sable Island is broadly supportive of this statement from the IPCC


## Method

We use generalized model from student t-distribution family with identity link function to analyze this question. 

$Y_i\sim T_{10}$ where $\sqrt{s\tau}(y-\eta)\sim T_v$, $\tau$ is the precision parameter, $s$ is a fixed scaling $s > 0$ and $\eta$ is the linear predictor. $T_v$ is a reparameterized standard Student-t with $v$ > 2 degrees of freedom with unit variance for all values of $v$.

Y is t-distribution with 10 degree of freedom. To verify if distribution of $Y$ met our assumption, histgram of $Y$ and simulated $T_10$ are given in Appendix. Based on the plot, we'd like to conclude that though two distribution does not match perfectly, the match is sufficiently good to conclude that this Assumption holds.

$E(Y)=X_i\beta+U_1(t_i)+U_2(t_i)+U_3(t_i)+V_i$

For this problem, we have 3 $U$, which stands for random effect. Two of them are random intercept while the other one is random slope. $week$ is the random slope term while $weekIid$ and $yearFac$ are the random intercept terms.

In order to find estimate of random effect, we need to use prior distribution. Penalized complexity prior is chosen for this problem. For pc prior, we need a value of $a$ for $P(\theta\ge a)\le0.05$. For two random intercept term, we use the same $a$, which is . Prior distribution for random slope term is different. We choose $a = 0.1/(52*100)$

Besides prior used to estimate random effect, we also have a prior distribution for degree of freedom

$V_i$ is the random noise.

## Result


```{r heatdataimport, include=FALSE}
x = readRDS('sableIsland.rds')
```

```{r,eval=FALSE}
x$month = as.numeric(format(x$Date, "%m"))
xSub = x[x$month %in% 5:10 & !is.na(x$Max.Temp...C.),]
weekValues = seq(min(xSub$Date), ISOdate(2030, 1, 1, 0, 0, 0, tz = "UTC"), by = "7 days")
xSub$week = cut(xSub$Date, weekValues)
xSub$weekIid = xSub$week
xSub$day = as.numeric(difftime(xSub$Date, min(weekValues), units = "days"))
xSub$cos12 = cos(xSub$day * 2 * pi/365.25)
xSub$sin12 = sin(xSub$day * 2 * pi/365.25)
xSub$cos6 = cos(xSub$day * 2 * 2 * pi/365.25)

xSub$sin6 = sin(xSub$day * 2 * 2 * pi/365.25)
xSub$yearFac = factor(format(xSub$Date, "%Y"))
lmStart = lm(Max.Temp...C. ~ sin12 + cos12 + sin6 + cos6, data = xSub)
startingValues = c(lmStart$fitted.values, rep(lmStart$coef[1], nlevels(xSub$week)), rep(0, nlevels(xSub$weekIid) + nlevels(xSub$yearFac)), lmStart$coef[-1])

INLA::inla.doc('^t$')

library("INLA")
mm = get("inla.models", INLA:::inla.get.inlaEnv())
if(class(mm) == 'function') mm = mm()
mm$latent$rw2$min.diff = NULL
assign("inla.models", mm, INLA:::inla.get.inlaEnv())

sableRes = INLA::inla(
  Max.Temp...C. ~ 0 + sin12 + cos12 + sin6 + cos6 +
    f(week, model='rw2',
      constr=FALSE,
      prior='pc.prec',
      param = c(0.1/(52*100), 0.05)) +
    f(weekIid, model='iid',
      prior='pc.prec',
      param = c(1, 0.5)) +
    f(yearFac, model='iid', prior='pc.prec',
      param = c(1, 0.5)),
  family='T',
  control.family = list(
    hyper = list(
      prec = list(prior='pc.prec', param=c(1, 0.5)),
      dof = list(prior='pc.dof', param=c(10, 0.5)))),
  control.mode = list(theta = c(-1,2,20,0,1),
                      x = startingValues, restart=TRUE),
  control.compute=list(config = TRUE),
  # control.inla = list(strategy='gaussian', int.strategy='eb'),
  data = xSub, verbose=TRUE)

sableRes$summary.hyper[, c(4, 3, 5)]

sableRes$summary.fixed[, c(4, 3, 5)]

Pmisc::priorPost(sableRes)$summary[, c(1, 3, 5)]

#####################################################################
mySample = inla.posterior.sample(n = 24, result = sableRes,
                                 num.threads = 8, selection = list(week =seq(1,nrow(sableRes$summary.random$week))))
length(mySample)
names(mySample[[1]])
weekSample = do.call(cbind, lapply(mySample, function(xx) xx$latent))
dim(weekSample)
head(weekSample)
plot(x$Date, x$Max.Temp...C., col = mapmisc::col2html("black",0.3))
forAxis = ISOdate(2016:2020, 1, 1, tz = "UTC")
plot(x$Date, x$Max.Temp...C., xlim = range(forAxis),
     xlab = "time", ylab = "degrees C", col = "red", xaxt = "n")
points(xSub$Date, xSub$Max.Temp...C.)
axis(1, forAxis, format(forAxis, "%Y"))
matplot(weekValues[-1], sableRes$summary.random$week[,paste0(c(0.5, 0.025, 0.975), "quant")], type = "l",
        lty = c(1, 2, 2), xlab = "time", ylab = "degrees C", xaxt = "n", col = "black", xaxs = "i")
forXaxis2 = ISOdate(seq(1880, 2040, by = 20), 1, 1,tz = "UTC")
axis(1, forXaxis2, format(forXaxis2, "%Y"))
myCol = mapmisc::colourScale(NA, breaks = 1:8, style = "unique",col = "Set2", opacity = 0.3)$col
matplot(weekValues[-1], weekSample, type = "l", lty = 1, col = myCol, xlab = "time", ylab = "degrees C",
        xaxt = "n", xaxs = "i")
axis(1, forXaxis2, format(forXaxis2, "%Y"))
```




# Appendix

## CO2

```{r dataimport, echo = FALSE}

co2s = read.table('daily_flask_co2_mlo.csv', header = FALSE, sep = ",",
                  skip = 69, stringsAsFactors = FALSE, 
                  col.names = c("day", "time", "junk1", "junk2", "Nflasks", "quality", "co2"))
co2s$date = strptime(paste(co2s$day, co2s$time), format = "%Y-%m-%d %H:%M",tz = "UTC")
# remove low-quality measurements 
co2s[co2s$quality >= 1, "co2"] = NA
plot_1 <- plot(co2s$date, co2s$co2, log = "y", cex = 0.3, col = "#00000040", xlab = "time", ylab = "ppm")
plot_2 <- plot(co2s[co2s$date > ISOdate(2015, 3, 1, tz = "UTC"), c("date", "co2")], log = "y", type = "o", xlab = "time", ylab = "ppm", cex = 0.5)


```

```{r, include = FALSE}
timeOrigin = ISOdate(1970, 1, 1, 0, 0, 0, tz = "UTC") 
co2s$days = as.numeric(difftime(co2s$date, timeOrigin, units = "days"))
co2s$cos12 = cos(2 * pi * co2s$days/365.25) 
co2s$sin12 = sin(2 * pi * co2s$days/365.25) 
co2s$cos6 = cos(2 * 2 * pi * co2s$days/365.25) 
co2s$sin6 = sin(2 * 2 * pi * co2s$days/365.25) 
cLm = lm(co2 ~ days + cos12 + sin12 + cos6 + sin6, data = co2s)
summary(cLm)$coef[, 1:2]


newX = data.frame(date = seq(ISOdate(1970, 1, 1, 0, 0, 0, tz = "UTC"), by = "1 days", length.out = 365 * 30))
newX$days = as.numeric(difftime(newX$date, timeOrigin, units = "days"))
newX$cos12 = cos(2 * pi * newX$days/365.25) 
newX$sin12 = sin(2 * pi * newX$days/365.25) 
newX$cos6 = cos(2 * 2 * pi * newX$days/365.25) 
newX$sin6 = sin(2 * 2 * pi * newX$days/365.25) 
coPred = predict(cLm, newX, se.fit = TRUE) 
coPred = data.frame(est = coPred$fit, lower = coPred$fit - 2 * coPred$se.fit, upper = coPred$fit + 2 * coPred$se.fit)

plot(newX$date, coPred$est, type = "l",main = '?', xlab = 'newX$data', ylab='coPred$est') 
matlines(as.numeric(newX$date), coPred[, c("lower", "upper", "est")], lty = 1, col = c("yellow", "yellow", "black"))
newX = newX[1:365, ] 
newX$days = 0
plot(newX$date, predict(cLm, newX))
```


```{r inla}
library("INLA")
# time random effect
timeBreaks = seq(min(co2s$date), ISOdate(2025, 1, 1,tz = "UTC"), by = "14 days")
timePoints = timeBreaks[-1]
co2s$timeRw2 = as.numeric(cut(co2s$date, timeBreaks))

# derivatives of time random effect
D = Diagonal(length(timePoints)) - bandSparse(length(timePoints), k = -1)
derivLincomb = inla.make.lincombs(timeRw2 = D[-1, ])
names(derivLincomb) = gsub("^lc", "time", names(derivLincomb))

# seasonal effect
StimeSeason = seq(ISOdate(2009, 9, 1, tz = "UTC"), ISOdate(2011, 3, 1, tz = "UTC"), len = 1001)
StimeYear = as.numeric(difftime(StimeSeason, timeOrigin,"days"))/365.35
seasonLincomb = inla.make.lincombs(sin12 = sin(2 * pi * StimeYear), cos12 = cos(2 * pi * StimeYear), sin6 = sin(2 * 2 * pi * StimeYear), cos6 = cos(2 * 2 * pi * StimeYear))
names(seasonLincomb) = gsub("^lc", "season", names(seasonLincomb))

# predictions
StimePred = as.numeric(difftime(timePoints, timeOrigin,
units = "days"))/365.35
predLincomb = inla.make.lincombs(timeRw2 = Diagonal(length(timePoints)),
`(Intercept)` = rep(1, length(timePoints)), sin12 = sin(2 * pi * StimePred), cos12 = cos(2 * pi * StimePred),
sin6 = sin(2 * 2 * pi * StimePred), cos6 = cos(2 * 2 * pi * StimePred))
names(predLincomb) = gsub("^lc", "pred", names(predLincomb))
StimeIndex = seq(1, length(timePoints))
timeOriginIndex = which.min(abs(difftime(timePoints, timeOrigin)))

# disable some error checking in INLA
library("INLA")
mm = get("inla.models", INLA:::inla.get.inlaEnv())
if(class(mm) == 'function') mm = mm()
mm$latent$rw2$min.diff = NULL
assign("inla.models", mm, INLA:::inla.get.inlaEnv())
co2res = inla(co2 ~ sin12 + cos12 + sin6 + cos6 +f(timeRw2, model = 'rw2', values = StimeIndex, prior='pc.prec', param = c(log(1.01)/26, 0.5)), data = co2s, family='gamma', lincomb = c(derivLincomb, seasonLincomb, predLincomb),
control.family = list(hyper=list(prec=list(prior='pc.prec', param=c(2, 0.5)))),verbose=TRUE)
# add this line if your computer has trouble
# control.inla = list(strategy='gaussian', int.strategy='eb'),

matplot(timePoints, exp(co2res$summary.random$timeRw2[,c("0.5quant", "0.025quant", "0.975quant")]), 
        type = "l", col = "black", lty = c(1, 2, 2), log = "y", xaxt = "n",
        xlab = "time", ylab = "ppm", main = 'random effect plot')
xax = pretty(timePoints)
axis(1, xax, format(xax, "%Y"))
derivPred = co2res$summary.lincomb.derived[grep("time", rownames(co2res$summary.lincomb.derived)), c("0.5quant", "0.025quant", "0.975quant")]
scaleTo10Years = (10 * 365.25/as.numeric(diff(timePoints, units = "days")))


matplot(timePoints[-1], scaleTo10Years * derivPred,
        type = "l", col = "black", lty = c(1, 2, 2), ylim = c(0,0.1), 
        xlim = range(as.numeric(co2s$date)), xaxs = "i", xaxt = "n", 
        xlab = "time", ylab = "log ppm, change per 10yr", main = 'Derivative plot')
axis(1, xax, format(xax, "%Y"))

abline(v = ISOdate(1973, 1, 1, tz = "UTC"), col = "blue")
abline(v = ISOdate(1980, 1, 1, tz = "UTC"), col = "blue")
abline(v = ISOdate(1982, 1, 1, tz = "UTC"), col = "blue")
abline(v = ISOdate(1989, 1, 1, tz = "UTC"), col = "blue")
abline(v = ISOdate(2001, 1, 1, tz = "UTC"), col = "blue")
abline(v = ISOdate(2008, 1, 1, tz = "UTC"), col = "blue")
abline(v = ISOdate(2015, 1, 1, tz = "UTC"), col = "blue")

matplot(StimeSeason, 
        exp(co2res$summary.lincomb.derived[grep("season", rownames(co2res$summary.lincomb.derived)),    
                                           c("0.5quant","0.025quant", "0.975quant")]), type = "l", col= "black",
        lty = c(1, 2, 2), log = "y", xaxs = "i", xaxt = "n",
        xlab = "time", ylab = "relative ppm", main = 'Seasonal plot')
xaxSeason = seq(ISOdate(2009, 9, 1, tz = "UTC"), by = "2 months", len = 20)
axis(1, xaxSeason, format(xaxSeason, "%b"))
timePred = co2res$summary.lincomb.derived[grep("pred", rownames(co2res$summary.lincomb.derived)), 
                                          c("0.5quant", "0.025quant", "0.975quant")]


matplot(timePoints, exp(timePred), type = "l", col = "black", lty = c(1, 2, 2), 
        log = "y", xlim = ISOdate(c(2010,2025), 1, 1, tz = "UTC"), ylim = c(390, 435), 
        xaxs = "i", xaxt = "n", xlab = "time", ylab = "ppm", main = 'Prediction plot')
xaxPred = seq(ISOdate(2010, 1, 1, tz = "UTC"), by = "5 years", len = 20)
axis(1, xaxPred, format(xaxPred, "%Y"))
```

## Heat

### Assumption

```{r}
studentT <- rt(500,10)
hist(studentT, prob = TRUE)

hist(xSub$)
```